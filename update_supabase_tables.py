#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è‡ªåŠ¨æ›´æ–°Supabaseæ•°æ®åº“è„šæœ¬
ä»resultæ–‡ä»¶å¤¹ä¸­æŸ¥æ‰¾æœ€æ–°çš„CSVæ–‡ä»¶å¹¶æ›´æ–°åˆ°å¯¹åº”çš„æ•°æ®åº“è¡¨ä¸­
ä½¿ç”¨supabase-pyå®¢æˆ·ç«¯è¿›è¡Œè¿æ¥
"""

import os
import sys
import glob
import pandas as pd
import json
from datetime import datetime
import logging
from supabase import create_client, Client
from dotenv import load_dotenv

class SupabaseUpdater:
    """
    Supabaseæ•°æ®åº“æ›´æ–°å™¨
    """
    
    def __init__(self):
        # åŠ è½½ç¯å¢ƒå˜é‡
        load_dotenv()
        
        # è·å–Supabaseé…ç½®
        self.supabase_url = os.getenv('SUPABASE_URL')
        self.supabase_key = os.getenv('SUPABASE_ANON_KEY')
        self.supabase: Client = None
        
        # è®¾ç½®æ—¥å¿—
        os.makedirs('logs', exist_ok=True)
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(f'logs/supabase_update_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log'),
                logging.StreamHandler(sys.stdout)
            ]
        )
        self.logger = logging.getLogger(__name__)
    
    def connect_to_database(self):
        """
        è¿æ¥åˆ°Supabaseæ•°æ®åº“
        """
        try:
            if not self.supabase_url or not self.supabase_key:
                raise ValueError("Supabaseé…ç½®ä¸å®Œæ•´ï¼Œè¯·æ£€æŸ¥.envæ–‡ä»¶")
            
            self.logger.info("æ­£åœ¨è¿æ¥åˆ°Supabaseæ•°æ®åº“...")
            self.supabase = create_client(self.supabase_url, self.supabase_key)
            
            # æµ‹è¯•è¿æ¥
            test_result = self.supabase.table('hiring_companies').select("*").limit(1).execute()
            if test_result.data is not None:
                self.logger.info("âœ… Supabaseæ•°æ®åº“è¿æ¥æˆåŠŸ")
                return True
            else:
                raise Exception("è¿æ¥æµ‹è¯•å¤±è´¥")
                
        except Exception as e:
            self.logger.error(f"âŒ æ•°æ®åº“è¿æ¥å¤±è´¥: {str(e)}")
            return False
    
    def find_latest_file(self, pattern):
        """
        æŸ¥æ‰¾æœ€æ–°çš„æ–‡ä»¶
        """
        try:
            # é¦–å…ˆåœ¨resultç›®å½•ä¸­æŸ¥æ‰¾
            result_files = glob.glob(f"result/{pattern}")
            # ç„¶ååœ¨æ ¹ç›®å½•ä¸­æŸ¥æ‰¾ï¼ˆå‘åå…¼å®¹ï¼‰
            root_files = glob.glob(pattern)
            
            all_files = result_files + root_files
            
            if not all_files:
                self.logger.warning(f"æœªæ‰¾åˆ°åŒ¹é…æ¨¡å¼ {pattern} çš„æ–‡ä»¶")
                return None
            
            # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼Œè¿”å›æœ€æ–°çš„æ–‡ä»¶
            latest_file = max(all_files, key=os.path.getmtime)
            self.logger.info(f"æ‰¾åˆ°æœ€æ–°æ–‡ä»¶: {latest_file}")
            return latest_file
            
        except Exception as e:
            self.logger.error(f"æŸ¥æ‰¾æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
            return None
    
    def get_table_record_count(self, table_name):
        """
        è·å–è¡¨çš„è®°å½•æ•°é‡
        """
        try:
            result = self.supabase.table(table_name).select("*", count="exact").execute()
            return result.count if hasattr(result, 'count') else 0
        except Exception as e:
            self.logger.warning(f"æ— æ³•è·å–è¡¨ {table_name} çš„è®°å½•æ•°: {str(e)}")
            return 0
    
    def clear_table(self, table_name):
        """
        æ¸…ç©ºè¡¨æ•°æ®
        """
        try:
            self.logger.info(f"æ­£åœ¨æ¸…ç©ºè¡¨ {table_name}...")
            
            # è·å–å½“å‰è®°å½•æ•°
            current_count = self.get_table_record_count(table_name)
            self.logger.info(f"è¡¨ {table_name} å½“å‰æœ‰ {current_count} æ¡è®°å½•")
            
            if current_count == 0:
                self.logger.info(f"è¡¨ {table_name} å·²ç»ä¸ºç©ºï¼Œè·³è¿‡æ¸…ç©ºæ“ä½œ")
                return True
            
            # åˆ é™¤æ‰€æœ‰è®°å½• - ä½¿ç”¨neqæ¥åˆ é™¤æ‰€æœ‰è®°å½•
            result = self.supabase.table(table_name).delete().neq('id', 0).execute()
            
            # éªŒè¯åˆ é™¤ç»“æœ
            new_count = self.get_table_record_count(table_name)
            self.logger.info(f"âœ… è¡¨ {table_name} æ¸…ç©ºå®Œæˆï¼Œå‰©ä½™è®°å½•: {new_count}")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ æ¸…ç©ºè¡¨ {table_name} å¤±è´¥: {str(e)}")
            return False
    
    def batch_insert_data(self, table_name, data, batch_size=100):
        """
        æ‰¹é‡æ’å…¥æ•°æ®
        """
        try:
            total_records = len(data)
            self.logger.info(f"å¼€å§‹æ‰¹é‡æ’å…¥ {total_records} æ¡è®°å½•åˆ°è¡¨ {table_name}")
            
            success_count = 0
            error_count = 0
            
            # åˆ†æ‰¹æ’å…¥
            for i in range(0, total_records, batch_size):
                batch_data = data[i:i + batch_size]
                batch_num = i // batch_size + 1
                total_batches = (total_records + batch_size - 1) // batch_size
                
                try:
                    self.logger.info(f"æ’å…¥ç¬¬ {batch_num}/{total_batches} æ‰¹æ•°æ® ({len(batch_data)} æ¡è®°å½•)")
                    
                    result = self.supabase.table(table_name).insert(batch_data).execute()
                    
                    if result.data:
                        success_count += len(batch_data)
                        self.logger.info(f"âœ… ç¬¬ {batch_num} æ‰¹æ’å…¥æˆåŠŸ")
                    else:
                        error_count += len(batch_data)
                        self.logger.error(f"âŒ ç¬¬ {batch_num} æ‰¹æ’å…¥å¤±è´¥: æ— è¿”å›æ•°æ®")
                        
                except Exception as batch_error:
                    error_count += len(batch_data)
                    self.logger.error(f"âŒ ç¬¬ {batch_num} æ‰¹æ’å…¥å¤±è´¥: {str(batch_error)}")
            
            self.logger.info(f"æ‰¹é‡æ’å…¥å®Œæˆ: æˆåŠŸ {success_count} æ¡ï¼Œå¤±è´¥ {error_count} æ¡")
            return success_count, error_count
            
        except Exception as e:
            self.logger.error(f"âŒ æ‰¹é‡æ’å…¥æ•°æ®å¤±è´¥: {str(e)}")
            return 0, len(data)
    
    def update_hiring_companies(self):
        """
        æ›´æ–°hiring_companiesè¡¨
        """
        try:
            self.logger.info("=" * 50)
            self.logger.info("å¼€å§‹æ›´æ–° hiring_companies è¡¨")
            
            # æŸ¥æ‰¾æœ€æ–°çš„å…¬å¸æ•°æ®æ–‡ä»¶
            latest_file = self.find_latest_file("all_hiring_companies_*.csv")
            if not latest_file:
                self.logger.error("æœªæ‰¾åˆ°å…¬å¸æ•°æ®æ–‡ä»¶")
                return False
            
            # è¯»å–CSVæ–‡ä»¶
            self.logger.info(f"æ­£åœ¨è¯»å–æ–‡ä»¶: {latest_file}")
            df = pd.read_csv(latest_file)
            
            # æ•°æ®é¢„å¤„ç†
            df = df.fillna('')  # å¡«å……ç©ºå€¼
            
            # è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨
            data = df.to_dict('records')
            self.logger.info(f"è¯»å–åˆ° {len(data)} æ¡å…¬å¸è®°å½•")
            
            # æ¸…ç©ºç°æœ‰æ•°æ®
            if not self.clear_table('hiring_companies'):
                return False
            
            # æ‰¹é‡æ’å…¥æ–°æ•°æ®
            success_count, error_count = self.batch_insert_data('hiring_companies', data)
            
            if error_count == 0:
                self.logger.info(f"âœ… hiring_companies è¡¨æ›´æ–°æˆåŠŸï¼Œå…± {success_count} æ¡è®°å½•")
                return True
            else:
                self.logger.warning(f"âš ï¸ hiring_companies è¡¨æ›´æ–°éƒ¨åˆ†æˆåŠŸ: {success_count} æˆåŠŸï¼Œ{error_count} å¤±è´¥")
                return success_count > 0
                
        except Exception as e:
            self.logger.error(f"âŒ æ›´æ–° hiring_companies è¡¨å¤±è´¥: {str(e)}")
            return False
    
    def update_yc_jobs(self):
        """
        æ›´æ–°yc_jobsè¡¨
        """
        try:
            self.logger.info("=" * 50)
            self.logger.info("å¼€å§‹æ›´æ–° yc_jobs è¡¨")
            
            # æŸ¥æ‰¾æœ€æ–°çš„èŒä½æ•°æ®æ–‡ä»¶
            latest_file = self.find_latest_file("all_jobs_*.csv")
            if not latest_file:
                self.logger.error("æœªæ‰¾åˆ°èŒä½æ•°æ®æ–‡ä»¶")
                return False
            
            # è¯»å–CSVæ–‡ä»¶
            self.logger.info(f"æ­£åœ¨è¯»å–æ–‡ä»¶: {latest_file}")
            df = pd.read_csv(latest_file)
            
            # æ•°æ®é¢„å¤„ç†
            df = df.fillna('')  # å¡«å……ç©ºå€¼
            
            # è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨
            data = df.to_dict('records')
            self.logger.info(f"è¯»å–åˆ° {len(data)} æ¡èŒä½è®°å½•")
            
            # æ¸…ç©ºç°æœ‰æ•°æ®
            if not self.clear_table('yc_jobs'):
                return False
            
            # æ‰¹é‡æ’å…¥æ–°æ•°æ®
            success_count, error_count = self.batch_insert_data('yc_jobs', data)
            
            if error_count == 0:
                self.logger.info(f"âœ… yc_jobs è¡¨æ›´æ–°æˆåŠŸï¼Œå…± {success_count} æ¡è®°å½•")
                return True
            else:
                self.logger.warning(f"âš ï¸ yc_jobs è¡¨æ›´æ–°éƒ¨åˆ†æˆåŠŸ: {success_count} æˆåŠŸï¼Œ{error_count} å¤±è´¥")
                return success_count > 0
                
        except Exception as e:
            self.logger.error(f"âŒ æ›´æ–° yc_jobs è¡¨å¤±è´¥: {str(e)}")
            return False
    
    def update_yc_jobs_join(self):
        """
        æ›´æ–°yc_jobs_joinè¡¨ï¼ˆåˆå¹¶åçš„æ•°æ®ï¼‰
        """
        try:
            self.logger.info("=" * 50)
            self.logger.info("å¼€å§‹æ›´æ–° yc_jobs_join è¡¨")
            
            # æŸ¥æ‰¾æœ€æ–°çš„åˆå¹¶æ•°æ®æ–‡ä»¶
            latest_file = self.find_latest_file("all_jobs_company_info_*.csv")
            if not latest_file:
                self.logger.error("æœªæ‰¾åˆ°åˆå¹¶æ•°æ®æ–‡ä»¶")
                return False
            
            # è¯»å–CSVæ–‡ä»¶
            self.logger.info(f"æ­£åœ¨è¯»å–æ–‡ä»¶: {latest_file}")
            df = pd.read_csv(latest_file)
            
            # æ•°æ®é¢„å¤„ç†
            df = df.fillna('')  # å¡«å……ç©ºå€¼
            
            # è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨
            data = df.to_dict('records')
            self.logger.info(f"è¯»å–åˆ° {len(data)} æ¡åˆå¹¶è®°å½•")
            
            # æ¸…ç©ºç°æœ‰æ•°æ®
            if not self.clear_table('yc_jobs_join'):
                return False
            
            # æ‰¹é‡æ’å…¥æ–°æ•°æ®
            success_count, error_count = self.batch_insert_data('yc_jobs_join', data)
            
            if error_count == 0:
                self.logger.info(f"âœ… yc_jobs_join è¡¨æ›´æ–°æˆåŠŸï¼Œå…± {success_count} æ¡è®°å½•")
                return True
            else:
                self.logger.warning(f"âš ï¸ yc_jobs_join è¡¨æ›´æ–°éƒ¨åˆ†æˆåŠŸ: {success_count} æˆåŠŸï¼Œ{error_count} å¤±è´¥")
                return success_count > 0
                
        except Exception as e:
            self.logger.error(f"âŒ æ›´æ–° yc_jobs_join è¡¨å¤±è´¥: {str(e)}")
            return False
    
    def run_update(self):
        """
        æ‰§è¡Œå®Œæ•´çš„æ•°æ®åº“æ›´æ–°æµç¨‹
        """
        try:
            self.logger.info("ğŸš€ å¼€å§‹Supabaseæ•°æ®åº“æ›´æ–°æµç¨‹")
            self.logger.info(f"â° æ›´æ–°æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
            
            # è¿æ¥æ•°æ®åº“
            if not self.connect_to_database():
                return False
            
            # æ›´æ–°å„ä¸ªè¡¨
            results = {
                'hiring_companies': self.update_hiring_companies(),
                'yc_jobs': self.update_yc_jobs(),
                'yc_jobs_join': self.update_yc_jobs_join()
            }
            
            # æ±‡æ€»ç»“æœ
            self.logger.info("=" * 50)
            self.logger.info("ğŸ“Š æ›´æ–°ç»“æœæ±‡æ€»:")
            
            success_count = 0
            for table_name, success in results.items():
                status = "âœ… æˆåŠŸ" if success else "âŒ å¤±è´¥"
                self.logger.info(f"   {table_name}: {status}")
                if success:
                    success_count += 1
            
            if success_count == len(results):
                self.logger.info("ğŸ‰ æ‰€æœ‰è¡¨æ›´æ–°æˆåŠŸï¼")
                return True
            elif success_count > 0:
                self.logger.warning(f"âš ï¸ éƒ¨åˆ†è¡¨æ›´æ–°æˆåŠŸ ({success_count}/{len(results)})")
                return True
            else:
                self.logger.error("âŒ æ‰€æœ‰è¡¨æ›´æ–°å¤±è´¥")
                return False
                
        except Exception as e:
            self.logger.error(f"âŒ æ›´æ–°æµç¨‹æ‰§è¡Œå¤±è´¥: {str(e)}")
            return False

def main():
    """
    ä¸»å‡½æ•°
    """
    print("ğŸš€ Supabaseæ•°æ®åº“æ›´æ–°å·¥å…·")
    print(f"â° å¯åŠ¨æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()
    
    updater = SupabaseUpdater()
    success = updater.run_update()
    
    print(f"\n{'='*50}")
    if success:
        print("âœ… æ•°æ®åº“æ›´æ–°å®Œæˆ")
        print("ğŸ’¡ æç¤ºï¼šæ‰€æœ‰è¡¨å·²æˆåŠŸæ›´æ–°åˆ°æœ€æ–°æ•°æ®")
    else:
        print("âŒ æ•°æ®åº“æ›´æ–°å¤±è´¥")
        print("ğŸ’¡ æç¤ºï¼šè¯·æ£€æŸ¥æ—¥å¿—æ–‡ä»¶äº†è§£è¯¦ç»†é”™è¯¯ä¿¡æ¯")
    
    return 0 if success else 1

if __name__ == "__main__":
    sys.exit(main())